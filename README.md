# ğŸ–ï¸ Viberr â€“ Feel the Words

**Viberr** is a real-time speech-to-vibration translation system for the deaf and hard-of-hearing. It transforms spoken language into finger-based vibration patterns using a unique 5-bit binary encoding system â€” enabling users to feel and interpret speech through touch.

> A new universal tactile language â€“ powered by binary, driven by empathy.

---

## ğŸŒŸ Features

- ğŸ¤ **Offline Voice Input** via [Vosk](https://github.com/alphacep/vosk-api)
- ğŸŒ **Multilingual Translation Support** (user toggleable)
- ğŸ”¡ **Binary Encoding** of letters into 5-bit vibration signals
- âœ‹ **Finger-Based Vibration Simulation** (console or UI)
- ğŸ§  **Interactive Trainer Web UI** to learn and practice patterns
- ğŸ•’ **Manual Speed Control** for vibration pace

---

## ğŸ“ Folder Structure

```
VIBRA_TRAINER_WEB/
â”œâ”€â”€ app.py                     # Flask + Vosk + simulation logic
â”œâ”€â”€ README.md                  # This file
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_words.json      # Words for training mode
â”‚
â”œâ”€â”€ mappings/
â”‚   â””â”€â”€ binary_map.json        # Binary letter mapping (Aâ€“Z)
â”‚
â”œâ”€â”€ models/
â”‚
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ script.js              # JS logic (UI, speed, animation)
â”‚   â””â”€â”€ style.css              # CSS for finger animations
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html             # Flask-rendered Trainer interface
â”‚
â”œâ”€â”€ viberr.git/                # Local Git repository metadata
â””â”€â”€ __pycache__/               # Python build cache
```

---
```

---

## ğŸ® How It Works

### ğŸ§ Stage 1: Voice-to-Vibration (Backend)
1. Live speech captured using microphone
2. Transcribed to English text using `vosk`
3. Text â†’ 5-bit binary code â†’ finger mapping
4. Console simulates finger vibrations (e.g., â€œThumb, Pinkyâ€)
5. User can adjust output speed

### ğŸŒ Stage 1.5: Trainer Web UI (Flask)
1. User clicks â€œNextâ€ to get a letter
2. Binary pattern shown as finger animation
3. User can guess the letter and receive feedback
4. Speed slider adjusts animation delay
5. Also supports simple words (optional)

---

## ğŸ”¢ Binary Mapping Logic

Each alphabet letter is encoded into a unique 5-bit pattern:

- Bit 1 â†’ Thumb  
- Bit 2 â†’ Index  
- Bit 3 â†’ Middle  
- Bit 4 â†’ Ring  
- Bit 5 â†’ Pinky

Example:
```text
Letter: H
Binary: 10101
Fingers Vibrated: Thumb, Middle, Pinky
```

- `11111` is reserved as a **break buzz** to indicate space or word separation.

Mapping is optimized using **Hamming distance** and **letter frequency**.

---

## âš™ï¸ Requirements

- Python 3.8+
- Flask
- vosk
- PyAudio (or sounddevice for some systems)

Install with:
```bash
pip install flask vosk pyaudio
```

---

## ğŸš€ Setup Instructions

1. Clone the repo:
```bash
git clone https://github.com/yourusername/viberr.git
cd viberr
```

2. Download a Vosk model (e.g., small English):
   https://alphacephei.com/vosk/models

3. Run the app:
```bash
python app.py
```

4. Open the web interface at:
```
http://localhost:5000
```

---

## ğŸ“Œ Roadmap

| Stage | Description |
|-------|-------------|
| âœ… Stage 1 | Real-time console output |
| âœ… Stage 1.5 | Web UI for training |
| ğŸ”œ Stage 2 | Hardware glove integration (vibration motors) |
| ğŸ”œ Stage 3 | ML-powered adaptive speed and feedback |
| ğŸ”œ Stage 4 | Mobile app with on-device inference (TinyML) |

---

## ğŸ“š Use Cases

- Live communication aid for deaf individuals
- Tactile speech learning for assistive education
- Emergency response and safety systems
- Prototype base for wearable haptics

---

## ğŸ§  Future Enhancements

- Glove-based hardware support via Raspberry Pi / Arduino
- Predictive next-letter suggestions
- User performance tracking and feedback loop
- Support for sentence context and grammar cues

---

## ğŸªª License

This project is licensed under the MIT License.  
Free to use, modify, and build upon.

---

## ğŸ™Œ Contributions

Have an idea or want to improve Viberr?  
Feel free to fork the repo, raise issues, or submit PRs.
